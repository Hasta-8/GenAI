{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Notebook Summary"
      ],
      "metadata": {
        "id": "sHL11om_Ue9L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2327272a"
      },
      "source": [
        "This notebook demonstrates how to build a question-answering system using Retrieval-Augmented Generation (RAG). It involves the following steps:\n",
        "\n",
        "1.  **Setting up the environment**: Installing necessary libraries like `chromadb`, `openai`, and `langchain`.\n",
        "2.  **Getting the dataset**: Downloading and unzipping a collection of articles.\n",
        "3.  **Loading and processing data**: Loading the articles, splitting them into smaller chunks, and creating embeddings for these chunks.\n",
        "4.  **Creating and loading a vector database**: Using ChromaDB to store the document chunks and their embeddings.\n",
        "5.  **Setting up a retriever**: Configuring a retriever to fetch relevant document chunks based on a query.\n",
        "6.  **Using an LLM for structured answers**: Integrating an OpenAI language model (LLM) with the retriever to generate answers based on the retrieved document chunks.\n",
        "7.  **Exploring different models**: Showing how to use different OpenAI models like `gpt-3.5-turbo-instruct` (default) and `gpt-4` for question answering.\n",
        "8.  **Zipping and Unzipping Database for resuse**: Showing how to zip and then unzip the database for reusing the embeddings.\n",
        "\n",
        "In essence, the notebook shows how to build a system that can answer questions by first finding relevant information in a large set of documents and then using an LLM to synthesize that information into a coherent answer."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Installing necessary packages**"
      ],
      "metadata": {
        "id": "-txbGJvXUlHL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa4c1e29",
        "outputId": "637f092d-30b9-4cab-b2ac-47c976a2549c",
        "collapsed": true
      },
      "source": [
        "!pip install -q chromadb openai langchain tiktoken langchain-community langchain-chroma langchain-openai --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UsWURnHHm8G5",
        "outputId": "51c44d44-fd9e-455e-e758-f6076e390999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: chromadb\n",
            "Version: 1.0.17\n",
            "Summary: Chroma.\n",
            "Home-page: https://github.com/chroma-core/chroma\n",
            "Author: \n",
            "Author-email: Jeff Huber <jeff@trychroma.com>, Anton Troynikov <anton@trychroma.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: bcrypt, build, grpcio, httpx, importlib-resources, jsonschema, kubernetes, mmh3, numpy, onnxruntime, opentelemetry-api, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-sdk, orjson, overrides, posthog, pybase64, pydantic, pypika, pyyaml, rich, tenacity, tokenizers, tqdm, typer, typing-extensions, uvicorn\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Getting the dataset of articles**"
      ],
      "metadata": {
        "id": "so0kPdyFueDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip"
      ],
      "metadata": {
        "id": "x8mGmg15nGb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q new_articles.zip -d new_articles"
      ],
      "metadata": {
        "id": "qP8TS7fgq2tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setting up environment**"
      ],
      "metadata": {
        "id": "iSfr4PiXukMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import TextLoader"
      ],
      "metadata": {
        "id": "R0AIuCA9unz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pWcNb9nqyn"
      },
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "# include your openai api key in the secrets section\n",
        "# of this notebook and turn the notebook access on.\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Data**"
      ],
      "metadata": {
        "id": "H086Do-zyDFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "\n",
        "loader = DirectoryLoader(\"/content/new_articles/\", glob = \"./*.txt\",\n",
        "                         loader_cls = TextLoader)\n",
        "document = loader.load()"
      ],
      "metadata": {
        "id": "u4vBKP8EyFE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Splitting into Chunks**"
      ],
      "metadata": {
        "id": "zyD_iC8ZASZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
        "chunks = text_splitter.split_documents(document)"
      ],
      "metadata": {
        "id": "l7cKrOCTy-OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Chunk 1: {chunks[0].page_content}\")\n",
        "print(f\"\\n==================================================================\\n\")\n",
        "print(f\"Chunk 2: {chunks[1].page_content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0ypN0nOpBDqZ",
        "outputId": "2e7ef94b-0720-4431-9f5e-6c2285c8a84c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1: Welcome back to This Week in Apps, the weekly TechCrunch series that recaps the latest in mobile OS news, mobile applications and the overall app economy.\n",
            "\n",
            "The app economy in 2023 hit a few snags, as consumer spending last year dropped for the first time by 2% to $167 billion, according to data.ai’s “State of Mobile” report. However, downloads are continuing to grow, up 11% year-over-year in 2022 to reach 255 billion. Consumers are also spending more time in mobile apps than ever before. On Android devices alone, hours spent in 2022 grew 9%, reaching 4.1 trillion.\n",
            "\n",
            "This Week in Apps offers a way to keep up with this fast-moving industry in one place with the latest from the world of apps, including news, updates, startup fundings, mergers and acquisitions, and much more.\n",
            "\n",
            "Do you want This Week in Apps in your inbox every Saturday? Sign up here: techcrunch.com/newsletters\n",
            "\n",
            "Top Stories\n",
            "\n",
            "Dorsey criticizes Twitter, Musk on the alternative social networks he’s backing\n",
            "\n",
            "==================================================================\n",
            "\n",
            "Chunk 2: Do you want This Week in Apps in your inbox every Saturday? Sign up here: techcrunch.com/newsletters\n",
            "\n",
            "Top Stories\n",
            "\n",
            "Dorsey criticizes Twitter, Musk on the alternative social networks he’s backing\n",
            "\n",
            "As demand for Bluesky, the Jack Dorsey-backed decentralized Twitter rival grows, the former Twitter CEO took to the app to share his thoughts on Twitter’s future, Elon Musk and the decision to take the company private. As TechCrunch’s Darrell Etherington reported, Dorsey responded to questions posed to him from other users and reporters on Bluesky, including one where he was asked if Musk has proven to be the best possible steward for the social network.\n",
            "\n",
            "Dorsey said he had not:\n",
            "\n",
            "No. Nor do I think he acted right after realizing his timing was bad. Nor do I think the board should have forced the sale. It all went south. But it happened and all we can do now is build something to avoid that ever happening again. So I’m happy Jay and team and nostr devs exist and building it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnPUZsw-BEfb",
        "outputId": "e70b7e6a-48a1-44f0-feec-987007377047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "233"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating DB object**"
      ],
      "metadata": {
        "id": "TmrQxGJcCAQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import embeddings\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "persist_directory = 'chromaDB'\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)"
      ],
      "metadata": {
        "id": "DK8YlSy7BSLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6277a6ce-cb40-4346-dece-f91b731c961e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4201335729.py:7: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma.from_documents(documents=chunks,\n",
        "                                 embedding=embeddings,\n",
        "                                 persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "5J1B5cwJDC-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading Data from the DB**"
      ],
      "metadata": {
        "id": "lDDbLGnEEqOK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36522b6c"
      },
      "source": [
        "# Now we can load the persisted database from disk, and use it as normal.\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "vectordb = Chroma(persist_directory=persist_directory,\n",
        "                  embedding_function=embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Make a retriever**"
      ],
      "metadata": {
        "id": "kzLWa-nTE_Mp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df8b9811"
      },
      "source": [
        "# default for search_kwargs is 4\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\":3})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.invoke(\"How much money did Microsoft raise?\")"
      ],
      "metadata": {
        "id": "yU6M7U-2FIG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeoJThoUFZ-u",
        "outputId": "4731887a-8f71-4c6d-9597-1016a529a10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def wrap_text(text, width):\n",
        "  return textwrap.fill(text, width=width)\n",
        "\n",
        "for index in range(len(docs)):\n",
        "  print(f\"Document_{index+1}\\n\\n{wrap_text(docs[index].page_content, 80)}\")\n",
        "  print(\"\\n================================================================\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PcVCtigYFtD8",
        "outputId": "85b78c2e-0718-4858-8761-ab7b1b5e3cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document_1\n",
            "\n",
            "April 28, 2023  VC firms including Sequoia Capital, Andreessen Horowitz, Thrive\n",
            "and K2 Global are picking up new shares, according to documents seen by\n",
            "TechCrunch. A source tells us Founders Fund is also investing. Altogether the\n",
            "VCs have put in just over $300 million at a valuation of $27 billion to $29\n",
            "billion. This is separate to a big investment from Microsoft announced earlier\n",
            "this year, a person familiar with the development told TechCrunch, which closed\n",
            "in January. The size of Microsoft’s investment is believed to be around $10\n",
            "billion, a figure we confirmed with our source.  April 25, 2023  Called ChatGPT\n",
            "Business, OpenAI describes the forthcoming offering as “for professionals who\n",
            "need more control over their data as well as enterprises seeking to manage their\n",
            "end users.”\n",
            "\n",
            "================================================================\n",
            "\n",
            "Document_2\n",
            "\n",
            "The amount that Google invested in the project was never disclosed, nor was the\n",
            "valuation of the exit to the parent company from the incubator, but the company\n",
            "has confirmed that there was a valuation and that it had grown since launch.\n",
            "The company is not disclosing how many customers it has in total but notes that\n",
            "they are in the sectors of gaming, health, finance, education and retail. A\n",
            "sampling includes Miniclip, Rovio, Kongregate, Crayola and Yousician and in\n",
            "total the number of customers represented by its customers is over 3 billion.\n",
            "Checks will sit in the Developer X division. “What Fergus, Nia, and the entire\n",
            "Google Checks team have accomplished is one of the hardest things to do. Their\n",
            "focus on customer needs and nimble execution has served them well, and we’re\n",
            "eager to push ahead in this next phase of Checks,” said Jeanine Banks in a\n",
            "statement.\n",
            "\n",
            "================================================================\n",
            "\n",
            "Document_3\n",
            "\n",
            "Partners of 3one4 Capital, a venture capital firm in India, recently went on a\n",
            "road show to raise a new fund. Within two and a half months, at the height of\n",
            "the worsening global economy, they had secured $200 million. It’s the fourth\n",
            "marquee fund for the Bengaluru-headquartered fund, whose portfolio includes four\n",
            "unicorn startups.  The fund, sixth overall for 3one4 Capital, was oversubscribed\n",
            "to $250 million but the firm is accepting only $200 million to keep itself lean\n",
            "and disciplined, said Pranav Pai, co-founder and partner at 3one4 Capital. The\n",
            "firm’s decision to limit the fund size is emblematic of its strategic choices,\n",
            "which have set it apart from other Indian venture firms.\n",
            "\n",
            "================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.search_type\n",
        "# its using cosine similarity to match the chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JdBdrOxqGO69",
        "outputId": "669bd26a-b341-4a7a-f014-a48e3d04252a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'similarity'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using LLM to get structured answer**"
      ],
      "metadata": {
        "id": "RRSKgxsOIoZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From vector DB i am getting the chunks of highest similarity to my question but not a definitive answer. So we will provide the question and chunks returned by vector DB to an LLM and ask it to provide a simple answer."
      ],
      "metadata": {
        "id": "aBOJekGgIsrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Making a chain**"
      ],
      "metadata": {
        "id": "1_bDroIcJLBR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66e20aa6"
      },
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(openai_api_key=openai.api_key),\n",
        "                                       chain_type=\"stuff\",\n",
        "                                       retriever=retriever,\n",
        "                                       return_source_documents=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full example\n",
        "query = \"How much money did Microsoft raise?\"\n",
        "result = qa_chain.invoke({\"query\": query})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kCi-dWGzKmFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C5KIDFETRz_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fe6b089"
      },
      "source": [
        "def query_output(result):\n",
        "  \"\"\"\n",
        "  Prints the result and source metadata from a RetrievalQA chain result.\n",
        "\n",
        "  Args:\n",
        "    result: A dictionary containing the result from a RetrievalQA chain.\n",
        "            Expected keys are 'result' and 'source_documents'.\n",
        "  \"\"\"\n",
        "  print(\"Answer:\")\n",
        "  print(result['result'])\n",
        "  print(\"\\nSource Documents:\")\n",
        "  for doc in result['source_documents']:\n",
        "    print(f\"- {doc.metadata['source']}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_output(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc0Fg__OSnT6",
        "outputId": "ae6bdffe-6efe-4965-ff02-c75b0df4b31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            " $10 billion\n",
            "\n",
            "Source Documents:\n",
            "- /content/new_articles/05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt\n",
            "- /content/new_articles/05-03-checks-the-ai-powered-data-protection-project-incubated-in-area-120-officially-exits-to-google.txt\n",
            "- /content/new_articles/05-07-3one4-capital-driven-by-contrarian-bets-raises-200-million-new-fund.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using different models**"
      ],
      "metadata": {
        "id": "ZjUig3svS64Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af1121d6"
      },
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Create the GPT-5 LLM instance\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-5\",               # Use GPT-5\n",
        "    openai_api_key=openai.api_key,\n",
        "    temperature=0                # Optional: deterministic responses\n",
        ")\n",
        "\n",
        "# create the chain to answer questions with a different model\n",
        "qa_chain_gpt5 = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                           chain_type=\"stuff\",\n",
        "                                           retriever=retriever,\n",
        "                                           return_source_documents=True)\n",
        "\n",
        "# For using models 3.5 and higher, ChatCompletionAI is necessary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full example\n",
        "query = \"How much money did Microsoft raise?\"\n",
        "result_gpt5 = qa_chain_gpt5.invoke({\"query\": query})"
      ],
      "metadata": {
        "id": "iCDceeXiMs8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_output(result_gpt5)"
      ],
      "metadata": {
        "id": "r7zJX1WjNSBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Zipping and Deleting the DB**"
      ],
      "metadata": {
        "id": "B5OOoB4CWYbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r chromaDB.zip ./chromaDB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BEcR0VLPWbYX",
        "outputId": "f28b6aa3-9240-400e-9d27-7210443d109f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: chromaDB/ (stored 0%)\n",
            "  adding: chromaDB/chroma.sqlite3 (deflated 41%)\n",
            "  adding: chromaDB/3a72c731-8121-4b82-9c79-fa4932685bd0/ (stored 0%)\n",
            "  adding: chromaDB/3a72c731-8121-4b82-9c79-fa4932685bd0/data_level0.bin (deflated 100%)\n",
            "  adding: chromaDB/3a72c731-8121-4b82-9c79-fa4932685bd0/header.bin (deflated 61%)\n",
            "  adding: chromaDB/3a72c731-8121-4b82-9c79-fa4932685bd0/length.bin (deflated 100%)\n",
            "  adding: chromaDB/3a72c731-8121-4b82-9c79-fa4932685bd0/link_lists.bin (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the directory\n",
        "!rm -rf chromaDB/"
      ],
      "metadata": {
        "id": "jnbx-1CjWvl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Reloading the DB from Zip File**"
      ],
      "metadata": {
        "id": "C50-KRDlXjiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip chromaDB.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgC19azIXiwd",
        "outputId": "865a6409-f973-42de-fc77-ac675030e10d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  chromaDB.zip\n",
            "   creating: chromaDB/\n",
            "  inflating: chromaDB/chroma.sqlite3  \n",
            "   creating: chromaDB/3a72c731-8121-4b82-9c79-fa4932685bd0/\n",
            "  inflating: chromaDB/3a72c731-8121-4b82-9c79-fa4932685bd0/data_level0.bin  \n",
            "  inflating: chromaDB/3a72c731-8121-4b82-9c79-fa4932685bd0/header.bin  \n",
            "  inflating: chromaDB/3a72c731-8121-4b82-9c79-fa4932685bd0/length.bin  \n",
            " extracting: chromaDB/3a72c731-8121-4b82-9c79-fa4932685bd0/link_lists.bin  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After unzipping we can restart the runtime using:"
      ],
      "metadata": {
        "id": "aCsjjrqxX6Fd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ae0e188"
      },
      "source": [
        "#from langchain_chroma import Chroma\n",
        "\n",
        "#vectordb = Chroma(persist_directory=persist_directory,\n",
        "#                  embedding_function=embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}